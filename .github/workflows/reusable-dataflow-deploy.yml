name: Reusable Dataflow Deploy

on:
  workflow_call:
    inputs:
      dataflow_path:
        required: false
        type: string
        default: '/home/runner/work/dataflow/dataflow/pubsub'
      job_name:
        required: false
        type: string
        default: 'pubsub-dataflow'
      pubsub_topic:
        required: false
        type: string
        default: 'test-topic'
    secrets:
      GCP_CREDENTIALS:
        required: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to Google Cloud
      id: gcp-auth
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_CREDENTIALS }}
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    - name: Set up gcloud CLI
      uses: google-github-actions/setup-gcloud@v2

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Python dependencies
      run: |
        echo "Current working directory: $(pwd)"
        pip install -r ${{ inputs.dataflow_path }}/requirements.txt

    - name: Launch Dataflow job
      run: |
        python ${{ inputs.dataflow_path }}/main.py \
          --runner=DataflowRunner \
          --project=$PROJECT_ID \
          --temp_location=gs://$BUCKET/temp \
          --region=$REGION \
          --job_name=${{ inputs.job_name }} \
          --input_topic=projects/$PROJECT_ID/topics/test-topic }}
      env:
        PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
        BUCKET: ${{ secrets.GCS_BUCKET }}
        REGION: ${{ secrets.GCP_REGION }}
